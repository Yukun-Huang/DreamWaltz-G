<h1 align="center">DreamWaltz-G: Expressive 3D Gaussian Avatars from Skeleton-Guided 2D Diffusion</h1>

<p align="center">

<div align="center">

<a href='https://arxiv.org/abs/2409.17145'><img src='https://img.shields.io/badge/arXiv-2409.17145-b31b1b.svg'></a> &nbsp;
<a href='https://yukun-huang.github.io/DreamWaltz-G/'><img src='https://img.shields.io/badge/Project-Page-Green'></a>

_**[Yukun Huang](https://scholar.google.com/citations?user=lHb5gzoAAAAJ),
[Jianan Wang](https://github.com/wendyjnwang),
[Ailing Zeng](https://ailingzeng.site),
[Zheng-Jun Zha](https://en.auto.ustc.edu.cn/2021/0616/c26828a513174/page.htm),
[Lei Zhang](https://www.leizhang.org),
[Xihui Liu](https://xh-liu.github.io)**_
<br>

</div>

## News
- Our code, pre-trained models, and results will be released in a few weeks.

## Introduction

<p align="middle">
<img src="assets/teaser.gif" width="100%">
<br>
<em><b>DreamWaltz-G</b> utilizes skeleton-guided 2D diffusion for text-to-3D avatar generation and expressive whole-body animation, which supports diverse applications like shape control & editing, 2D video reenactment, and 3D scene composition.</em>
</p>

